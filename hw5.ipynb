{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from scipy.stats.mstats import winsorize\n",
    "from linearmodels.panel import PanelOLS\n",
    "import wrds\n",
    "import time\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hw_ETF(object):\n",
    "    \"\"\"\n",
    "    Class to replicate the flow sensitivity analysis in Goldstein et al. (2017).\n",
    "    You will need to implement the methods in this class, wherever there is a TODO.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fund_summary_df = None\n",
    "        self.shares_df = None\n",
    "        self.impute_basket_df = None\n",
    "        self.merged_df = None\n",
    "\n",
    "    def clean_fund_summary(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_summary_2019_2023.csv, which you can download with the codes below\n",
    "        '''\n",
    "        df_fund_summary_query = \"SELECT * FROM crsp_q_mutualfunds.fund_summary2 WHERE (caldt BETWEEN '2019-01-01' AND '2023-12-31')\"\n",
    "        df = db.raw_sql(df_fund_summary_query)\n",
    "        df.to_csv(data_path + \"/crsp_q_mutualfunds_summary_2019_2023.csv\", index=False)\n",
    "        '''\n",
    "        df = pd.read_csv(filename, encoding='ISO-8859-1', low_memory=False)\n",
    "        df['caldt'] = pd.to_datetime(df['caldt'])\n",
    "\n",
    "        exclude = '|'.join(['Treasury', 'U.S. Government', 'Municipal', 'Emerging Market', 'Emerging Mrkts', 'International', 'Global'])\n",
    "        df = df[(df['et_flag'] == 'F') & (df['index_fund_flag'] == 'D') & \n",
    "                (df['crsp_obj_cd'] == 'I') & (~df['lipper_class_name'].str.contains(exclude, case=False, na=False)) &\n",
    "                (~df['fund_name'].str.contains(exclude, case=False, na=False)) & (df['caldt'].dt.year == 2020)]\n",
    "\n",
    "        df = df.drop_duplicates(subset='crsp_portno')\n",
    "\n",
    "        self.fund_summary_df = df\n",
    "        return df['crsp_portno'].dropna().astype(int).tolist(), df['ticker'].dropna().tolist()\n",
    "\n",
    "    def clean_shares(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_shares_2020.csv\n",
    "        # Import shares data: CRSP monthly stock file; shrout (Number of Shares Outstanding in thousands). Query ETF tickers above, 2019m12 - 2021m1 \n",
    "        # the data is also available on Canvas\n",
    "        shares_df = pd.read_csv(filename, parse_dates=['date'])\n",
    "        shares_df.sort_values(by=['PERMNO', 'date'], inplace=True)\n",
    "\n",
    "        # Calculate pct_change directly\n",
    "        shares_df['etf_shares_change'] = shares_df.groupby('PERMNO')['SHROUT'].pct_change()\n",
    "        shares_df['month'] = shares_df['date'].dt.month\n",
    "        shares_df['year'] = shares_df['date'].dt.year\n",
    "\n",
    "        self.shares_df = shares_df\n",
    "        return shares_df['etf_shares_change'].dropna().tolist()\n",
    "\n",
    "    def impute_baskets(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_holdings_2020.csv, which you can download with the codes below\n",
    "        '''\n",
    "        df_query_holdings = \"SELECT * FROM crsp.holdings WHERE (report_dt BETWEEN '2019-12-01' AND '2021-01-31')\"\n",
    "        merged_df = db.raw_sql(df_query_holdings)\n",
    "        merged_df.to_csv(f\"{data_path}/crsp_q_mutualfunds_holdings_2020.csv\", index=False)\n",
    "        '''\n",
    "        df = pd.read_csv(filename)\n",
    "        df['cusip'].fillna(df['security_name'], inplace=True)\n",
    "        df.sort_values(by=['crsp_portno', 'report_dt'], inplace=True)\n",
    "        df['shares_change'] = df.groupby(['crsp_portno', 'cusip'])['nbr_shares'].diff()\n",
    "        df['imputed_basket_weight_level'] = df.groupby(['crsp_portno', 'report_dt'])['shares_change'].transform(lambda x: abs(x).sum())\n",
    "        \n",
    "        # Calculate unique securities\n",
    "        df = df.assign(\n",
    "            portfolio_num_sec=df.groupby(['crsp_portno', 'report_dt'])['cusip'].transform('nunique'),\n",
    "            basket_num_sec=df[df['shares_change'] != 0].groupby(['crsp_portno', 'report_dt'])['cusip'].transform('nunique')\n",
    "        ).fillna({'imputed_basket_weight_level': 0, 'portfolio_num_sec': 0, 'basket_num_sec': 0})\n",
    "        \n",
    "        self.impute_basket_df = df\n",
    "        return df['portfolio_num_sec'].tolist(), df['basket_num_sec'].tolist()\n",
    "    \n",
    "    \n",
    "    def merge_summary_shares(self):\n",
    "        merged = pd.merge(self.fund_summary_df, self.impute_basket_df, on='crsp_portno', how='inner')\n",
    "        merged['report_dt'] = pd.to_datetime(merged['report_dt'])\n",
    "        merged = merged.assign(year=merged['report_dt'].dt.year, month=merged['report_dt'].dt.month)\n",
    "\n",
    "        merged.rename(columns={'ticker_x': 'ticker'}, inplace=True)\n",
    "        merged.drop(columns=['ticker_y'], inplace=True)\n",
    "\n",
    "\n",
    "        shares = self.shares_df.rename(columns={'TICKER': 'ticker'})\n",
    "        shares = shares.dropna(subset=['ticker', 'year', 'month'])\n",
    "        final_merged = pd.merge(merged, shares, on=['ticker', 'year', 'month'], how='inner')\n",
    "        \n",
    "        self.merged_df = final_merged\n",
    "        return final_merged.head(5)\n",
    "    \n",
    "\n",
    "    def analysis(self):\n",
    "        df = self.merged_df.drop_duplicates(subset=['ticker', 'month', 'year'])\n",
    "        df = df[(df['portfolio_num_sec'] > 0) & (df['basket_num_sec'] > 0)]\n",
    "\n",
    "        num_ETFs = df['ticker'].nunique()\n",
    "        avg_bonds_portfolio = df['portfolio_num_sec'].mean()\n",
    "        avg_bonds_basket = df['basket_num_sec'].mean()\n",
    "        avg_basket_frac = (df['basket_num_sec'] / df['portfolio_num_sec']).mean()\n",
    "\n",
    "        return num_ETFs, avg_bonds_portfolio, avg_bonds_basket, avg_basket_frac\n",
    "    \n",
    "    def analysis_verbal(self):\n",
    "        '''\n",
    "        Please type your response to the question: \n",
    "        For each ETF, calculate average number of bonds in the basket and in the ETF holdings. Divide the average number of bonds in baskets by the number of bonds in the ETF holdings. What do you observe?\n",
    "        '''\n",
    "        reponse = \"Baskets are crucial in shaping monthly ETF portfolio adjustments, far beyond being mere representative samples. Their substantial share underscores the importance of basket composition in affecting the portfolio's structure and the liquidity of its bonds.\"\n",
    "        return reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hw_ETF(object):\n",
    "    \"\"\"\n",
    "    Class to replicate the flow sensitivity analysis in Goldstein et al. (2017).\n",
    "    You will need to implement the methods in this class, wherever there is a TODO.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fund_summary_df = None\n",
    "        self.shares_df = None\n",
    "        self.impute_basket_df = None\n",
    "        self.merged_df = None\n",
    "\n",
    "    def clean_fund_summary(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_summary_2019_2023.csv, which you can download with the codes below\n",
    "        '''\n",
    "        df_fund_summary_query = \"SELECT * FROM crsp_q_mutualfunds.fund_summary2 WHERE (caldt BETWEEN '2019-01-01' AND '2023-12-31')\"\n",
    "        df = db.raw_sql(df_fund_summary_query)\n",
    "        df.to_csv(data_path + \"/crsp_q_mutualfunds_summary_2019_2023.csv\", index=False)\n",
    "        '''\n",
    "        df = pd.read_csv(filename, encoding='ISO-8859-1', low_memory=False)\n",
    "\n",
    "        # Convert 'caldt' to datetime format to ensure correct filtering by year\n",
    "        df['caldt'] = pd.to_datetime(df['caldt'])\n",
    "\n",
    "        # Do the following manipulations with df:\n",
    "            # Filter data: ETFs, Index funds, Fixed income\n",
    "            # Exclude certain categories\n",
    "            # Keep date range of interest: 2020\n",
    "            # Drop duplicates in crsp_portno\n",
    "            # Save processed dataset\n",
    "\n",
    "        ### Filter fund types\n",
    "        # Keep ETFs (assuming 'et_flag' indicates ETFs; adjust as needed)\n",
    "        # Index funds (assuming 'index_fund_flag' indicates index funds; adjust as needed)\n",
    "        # Fixed income funds, i.e., if the CRSP objective code is 'I'\n",
    "        df_filtered = df[\n",
    "            (df['et_flag'] == 'F') &  \n",
    "            (df['index_fund_flag'] == 'D') &\n",
    "            (df['crsp_obj_cd'] == 'I')\n",
    "        ]\n",
    "\n",
    "        # Exclude certain categories based on lipper_class_name and fund_name\n",
    "        exclude_categories = ['Treasury', 'U.S. Government', 'Municipal', 'Emerging Market', 'Emerging Mrkts', 'International', 'Global']\n",
    "        for category in exclude_categories:\n",
    "            df_filtered = df_filtered[~df_filtered['lipper_class_name'].str.contains(category, case=False, na=False)]\n",
    "            df_filtered = df_filtered[~df_filtered['fund_name'].str.contains(category, case=False, na=False)]\n",
    "\n",
    "        # Keep observations for 2020 only\n",
    "        df_filtered = df_filtered[df_filtered['caldt'].dt.year == 2020]\n",
    "\n",
    "        # Drop duplicates in terms of fund identifier: crsp_portno\n",
    "        df_filtered = df_filtered.drop_duplicates(subset=['crsp_portno'])\n",
    "            \n",
    "        # Save processed data\n",
    "        # please keep this\n",
    "        self.fund_summary_df = df_filtered\n",
    "\n",
    "        df = df_filtered\n",
    "        \n",
    "        # return the following lists for grading\n",
    "        portnos_list = df['crsp_portno'].dropna().astype(int).tolist()\n",
    "        etftickers_list = df['ticker'].dropna().tolist()\n",
    "        return portnos_list, etftickers_list\n",
    "\n",
    "    def clean_shares(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_shares_2020.csv\n",
    "        # Import shares data: CRSP monthly stock file; shrout (Number of Shares Outstanding in thousands). Query ETF tickers above, 2019m12 - 2021m1 \n",
    "        # the data is also available on Canvas\n",
    "        # Load dataset\n",
    "        shares_df = pd.read_csv('crsp_q_mutualfunds_shares_2020.csv', parse_dates=['date'])\n",
    "\n",
    "        # Sort by PERMNO and date to ensure the calculation is done in chronological order for each ETF\n",
    "        shares_df.sort_values(by=['PERMNO', 'date'], inplace=True)\n",
    "\n",
    "        # Calculate proportional change in shares outstanding from month to month\n",
    "        shares_df['etf_shares_change'] = shares_df.groupby('PERMNO')['SHROUT'].pct_change()\n",
    "\n",
    "        # Generate year and month variables for merging later\n",
    "        shares_df['year'] = shares_df['date'].dt.year\n",
    "        shares_df['month'] = shares_df['date'].dt.month\n",
    "\n",
    "        # Save processed data\n",
    "        # please keep this\n",
    "        self.shares_df = shares_df\n",
    "\n",
    "        # return the following lists for grading\n",
    "        etf_shares_change_list = shares_df['etf_shares_change'].dropna().to_list()\n",
    "        return etf_shares_change_list\n",
    "\n",
    "    def impute_baskets(self, filename):\n",
    "        # for this part, you work with crsp_q_mutualfunds_holdings_2020.csv, which you can download with the codes below\n",
    "        '''\n",
    "        df_query_holdings = \"SELECT * FROM crsp.holdings WHERE (report_dt BETWEEN '2019-12-01' AND '2021-01-31')\"\n",
    "        merged_df = db.raw_sql(df_query_holdings)\n",
    "        merged_df.to_csv(f\"{data_path}/crsp_q_mutualfunds_holdings_2020.csv\", index=False)\n",
    "        '''\n",
    "        impute_basket_df = pd.read_csv(filename)\n",
    "\n",
    "        # handle any missing cusips: Replace missing cusips with name of security\n",
    "        # Replace missing CUSIPs with the name of security\n",
    "        impute_basket_df['cusip'].fillna(impute_basket_df['security_name'], inplace=True)\n",
    "        \n",
    "        # Sort by ETF (crsp_portno) and report date to ensure chronological processing\n",
    "        impute_basket_df.sort_values(by=['crsp_portno', 'report_dt'], inplace=True)\n",
    "        \n",
    "        # Calculate changes in the number of shares held of a given security by an ETF across months\n",
    "        impute_basket_df['shares_change'] = impute_basket_df.groupby(['crsp_portno', 'cusip'])['nbr_shares'].diff()\n",
    "\n",
    "        # impute (intensive margin) basket: Impute intensive margin basket by taking changes in the number of shares held of a given bond (cusip) by an ETF (portno) across months\n",
    "        impute_basket_df['imputed_basket_weight_level'] = impute_basket_df.groupby(['crsp_portno', 'report_dt'])['shares_change'].transform(lambda x: abs(x) / abs(x).sum())\n",
    "\n",
    "        # Track number of bonds in portfolio and baskets\n",
    "        # Calculate the number of bonds held in basket and holdings by each ETF in each month\n",
    "        portfolio_num_sec = impute_basket_df.groupby(['crsp_portno', 'report_dt'])['cusip'].nunique().reset_index(name='portfolio_num_sec')\n",
    "        impute_basket_df = pd.merge(impute_basket_df, portfolio_num_sec, on=['crsp_portno', 'report_dt'], how='left')\n",
    "        basket_num_sec = impute_basket_df[impute_basket_df['shares_change'] != 0].groupby(['crsp_portno', 'report_dt'])['cusip'].nunique().reset_index(name='basket_num_sec')\n",
    "        impute_basket_df = pd.merge(impute_basket_df, basket_num_sec, on=['crsp_portno', 'report_dt'], how='left')\n",
    "\n",
    "        # Fill NaN values for 'imputed_basket_weight_level', 'portfolio_num_sec', and 'basket_num_sec' where no changes occurred\n",
    "        impute_basket_df['imputed_basket_weight_level'].fillna(0, inplace=True)\n",
    "        impute_basket_df['portfolio_num_sec'].fillna(0, inplace=True)\n",
    "        impute_basket_df['basket_num_sec'].fillna(0, inplace=True)\n",
    "\n",
    "        # Save processed data\n",
    "        # please keep this\n",
    "        self.impute_basket_df = impute_basket_df\n",
    "\n",
    "        # return the following lists for grading\n",
    "        portfolio_num_sec_list = impute_basket_df['portfolio_num_sec'].dropna().to_list()\n",
    "        basket_num_sec_list = impute_basket_df['basket_num_sec'].dropna().to_list()\n",
    "        return portfolio_num_sec_list, basket_num_sec_list\n",
    "    \n",
    "    \n",
    "    def merge_summary_shares(self):\n",
    "        fundsummary_df = self.fund_summary_df\n",
    "        impute_basket_df = self.impute_basket_df\n",
    "        shares_df = self.shares_df\n",
    "\n",
    "        # Merge data from step 1 and step 3, based on 'crsp_portno'\n",
    "        fundsummary_df['crsp_portno'] = fundsummary_df['crsp_portno'].astype(float)\n",
    "        merged_df = pd.merge(fundsummary_df, impute_basket_df, on='crsp_portno', how='inner')\n",
    "\n",
    "        # Before merging with shares_df, ensure there's a common 'year' and 'month' in merged_df\n",
    "        merged_df['report_dt'] = pd.to_datetime(merged_df['report_dt'])\n",
    "        merged_df['year'] = merged_df['report_dt'].dt.year\n",
    "        merged_df['month'] = merged_df['report_dt'].dt.month\n",
    "\n",
    "        ## Checks\n",
    "        # Retrieve all column names\n",
    "        columns = merged_df.columns\n",
    "\n",
    "        # Print all column names\n",
    "        print(\"Columns in merged_df:\", list(columns))\n",
    "\n",
    "        # Rename 'ticker_x' to 'ticker' and drop 'ticker_y'\n",
    "        merged_df.rename(columns={'ticker_x': 'ticker'}, inplace=True)\n",
    "        merged_df.drop(columns=['ticker_y'], inplace=True)\n",
    "\n",
    "        shares_df = shares_df.rename(columns={'TICKER': 'ticker'})\n",
    "\n",
    "        # Filter out rows with missing values in the join columns\n",
    "        merged_df = merged_df.dropna(subset=['ticker', 'year', 'month'])\n",
    "        shares_df = shares_df.dropna(subset=['ticker', 'year', 'month'])\n",
    "\n",
    "        '''\n",
    "        ## Merge to ETF Shares from step 2, based on ticker-month-year\n",
    "        # Perform the merge in chunks due to huge file size\n",
    "        chunk_size = 200000  # Adjust the chunk size as needed\n",
    "        merged_chunks = []\n",
    "\n",
    "        for chunk_start in range(0, shares_df.shape[0], chunk_size):\n",
    "            chunk_end = min(chunk_start + chunk_size, shares_df.shape[0])\n",
    "            shares_chunk = shares_df[chunk_start:chunk_end]\n",
    "            merged_chunk = pd.merge(merged_df, shares_chunk,\n",
    "                                    on=['ticker', 'year', 'month'], how='inner')\n",
    "            merged_chunks.append(merged_chunk)\n",
    "\n",
    "        # Concatenate the merged chunks\n",
    "        merged_df = pd.concat(merged_chunks, ignore_index=True)\n",
    "        '''\n",
    "\n",
    "        merged_df = pd.merge(merged_df, shares_df, on=['ticker', 'year', 'month'], how='inner')    \n",
    "\n",
    "        # Save processed data\n",
    "        # please keep this\n",
    "        self.merged_df = merged_df\n",
    "        \n",
    "        # return the following for grading\n",
    "        return merged_df.head(5)\n",
    "\n",
    "    def analysis(self):\n",
    "        merged_df = self.merged_df\n",
    "        \n",
    "        # Do the following manipulations with merged_df:\n",
    "            # Drop duplicates by etf-month \n",
    "            # Remove rows where number of holdings is missing or 0\n",
    "            # Calculate baskets_frac\n",
    "        \n",
    "        # Drop duplicates by ETF-month, assuming 'ticker' and 'month' uniquely identify each ETF's monthly data\n",
    "        merged_df = merged_df.drop_duplicates(subset=['ticker', 'month', 'year'])\n",
    "\n",
    "        # Remove rows where number of holdings is missing or 0\n",
    "        merged_df = merged_df[(merged_df['portfolio_num_sec'] > 0) & (merged_df['basket_num_sec'] > 0)]\n",
    "\n",
    "        # Number of ETFs: Assuming 'ticker' uniquely identifies each ETF\n",
    "        num_ETFs = merged_df['ticker'].nunique()\n",
    "\n",
    "        # average number of bonds in portfolio \n",
    "        avg_bonds_portfolio = merged_df['portfolio_num_sec'].mean()\n",
    "\n",
    "        # average number of bonds in basket\n",
    "        avg_bonds_basket = merged_df['basket_num_sec'].mean()\n",
    "\n",
    "        # Calculate the fraction of bonds in basket relative to portfolio for each ETF each month\n",
    "        merged_df['baskets_frac'] = merged_df['basket_num_sec'] / merged_df['portfolio_num_sec']\n",
    "\n",
    "        # average fraction of bonds in basket relative to portfolio\n",
    "        avg_basket_frac = merged_df['baskets_frac'].mean()\n",
    "        \n",
    "        # return the following for grading\n",
    "        return num_ETFs, avg_bonds_portfolio, avg_bonds_basket, avg_basket_frac\n",
    "    \n",
    "    def analysis_verbal(self):\n",
    "        '''\n",
    "        Please type your response to the question: \n",
    "        For each ETF, calculate average number of bonds in the basket and in the ETF holdings. Divide the average number of bonds in baskets by the number of bonds in the ETF holdings. What do you observe?\n",
    "        '''\n",
    "        reponse = \"The analysis reveals that, on average, the ETF baskets contain a significant portion of the bonds held in the overall ETF portfolio. Specifically, the average fraction of bonds in the basket relative to the portfolio (avg_basket_frac) is approximately 0.5517, indicating that the baskets comprise about 55% of the total bond holdings in the ETFs. This suggests that the creation and redemption baskets play a substantial role in the monthly changes of ETF portfolio holdings. The high proportion of basket bonds relative to the total portfolio implies that the baskets are not just a small, representative sample of the ETF holdings but rather constitute a significant portion of the ETF's total bond exposure. This finding highlights the importance of understanding the composition of ETF baskets, as they can have a considerable impact on the overall portfolio structure and the liquidity of the underlying bonds.\"\n",
    "        return reponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in merged_df: ['summary_period2', 'crsp_fundno', 'caldt', 'summary_period', 'nav_latest', 'nav_latest_dt', 'tna_latest', 'tna_latest_dt', 'yield', 'div_ytd', 'cap_gains_ytd', 'nav_52w_h', 'nav_52w_h_dt', 'nav_52w_l', 'nav_52w_l_dt', 'unrealized_app_dep', 'unrealized_app_dt', 'asset_dt', 'per_com', 'per_pref', 'per_conv', 'per_corp', 'per_muni', 'per_govt', 'per_oth', 'per_cash', 'per_bond', 'per_abs', 'per_mbs', 'per_eq_oth', 'per_fi_oth', 'maturity', 'maturity_dt_x', 'cusip8', 'crsp_portno', 'crsp_cl_grp', 'fund_name', 'ticker_x', 'ncusip', 'mgmt_name', 'mgmt_cd', 'mgr_name', 'mgr_dt', 'adv_name', 'open_to_inv', 'retail_fund', 'inst_fund', 'm_fund', 'index_fund_flag', 'vau_fund', 'et_flag', 'delist_cd', 'header', 'first_offer_dt', 'end_dt', 'dead_flag', 'merge_fundno', 'actual_12b1', 'max_12b1', 'mgmt_fee', 'exp_ratio', 'turn_ratio', 'fiscal_yearend', 'crsp_obj_cd', 'si_obj_cd', 'accrual_fund', 'sales_restrict', 'wbrger_obj_cd', 'policy', 'lipper_class', 'lipper_class_name', 'lipper_obj_cd', 'lipper_obj_name', 'lipper_asset_cd', 'lipper_tax_cd', 'report_dt', 'security_rank', 'eff_dt', 'percent_tna', 'nbr_shares', 'market_val', 'crsp_company_key', 'security_name', 'cusip', 'permno', 'permco', 'ticker_y', 'coupon', 'maturity_dt_y', 'shares_change', 'imputed_basket_weight_level', 'portfolio_num_sec', 'basket_num_sec', 'year', 'month']\n",
      "  summary_period2  crsp_fundno      caldt summary_period  nav_latest  \\\n",
      "0               Q      16417.0 2020-03-31              Q      115.32   \n",
      "1               Q      16417.0 2020-03-31              Q      115.32   \n",
      "2               Q      16417.0 2020-03-31              Q      115.32   \n",
      "3               Q      16417.0 2020-03-31              Q      115.32   \n",
      "4               Q      16417.0 2020-03-31              Q      115.32   \n",
      "\n",
      "  nav_latest_dt  tna_latest tna_latest_dt     yield   div_ytd  ...  \\\n",
      "0    2020-03-31     68339.7    2020-03-31  0.002073  0.239027  ...   \n",
      "1    2020-03-31     68339.7    2020-03-31  0.002073  0.239027  ...   \n",
      "2    2020-03-31     68339.7    2020-03-31  0.002073  0.239027  ...   \n",
      "3    2020-03-31     68339.7    2020-03-31  0.002073  0.239027  ...   \n",
      "4    2020-03-31     68339.7    2020-03-31  0.002073  0.239027  ...   \n",
      "\n",
      "   shares_change  imputed_basket_weight_level portfolio_num_sec  \\\n",
      "0            NaN                          0.0              7573   \n",
      "1            NaN                          0.0              7573   \n",
      "2            NaN                          0.0              7573   \n",
      "3            NaN                          0.0              7573   \n",
      "4            NaN                          0.0              7573   \n",
      "\n",
      "   basket_num_sec  year  month  PERMNO       date    SHROUT  etf_shares_change  \n",
      "0          7573.0  2019     12   89848 2019-12-31  616200.0                NaN  \n",
      "1          7573.0  2019     12   89848 2019-12-31  616200.0                NaN  \n",
      "2          7573.0  2019     12   89848 2019-12-31  616200.0                NaN  \n",
      "3          7573.0  2019     12   89848 2019-12-31  616200.0                NaN  \n",
      "4          7573.0  2019     12   89848 2019-12-31  616200.0                NaN  \n",
      "\n",
      "[5 rows x 98 columns]\n",
      "15 3263.2815533980583 1870.7427184466019 0.692895339103062\n"
     ]
    }
   ],
   "source": [
    "hw = hw_ETF()\n",
    "\n",
    "# To download the files \"MonthlyReturns.csv\" and \"fund_summary_full.csv\" from WRDS\n",
    "# If you have already saved these files, you can comment out the following lines\n",
    "\n",
    "# Homework begins here:\n",
    "# Step 1: Download and clean data\n",
    "# the data will be provided and data downloading will not be tested in this homework\n",
    "portnos_list, etftickers_list = hw.clean_fund_summary('./crsp_q_mutualfunds_summary_2019_2023.csv')\n",
    "# print(portnos_list, etftickers_list)\n",
    "\n",
    "# Step 2: Calculate monthly changes in ETF shares\n",
    "etf_shares_change = hw.clean_shares('./crsp_q_mutualfunds_shares_2020.csv')\n",
    "# print(etf_shares_change)\n",
    "\n",
    "# Step 3: Impute baskets from monthly changes in ETF holdings\n",
    "portfolio_num_sec_list, basket_num_sec_list = hw.impute_baskets('./crsp_q_mutualfunds_holdings_2020.csv')\n",
    "# print(portfolio_num_sec_list, basket_num_sec_list)\n",
    "\n",
    "# Step 4: Merge variables: ETF ticker from Fund Summary; ETF Shares from Monthly Stock\n",
    "df_sample = hw.merge_summary_shares()\n",
    "print(df_sample)\n",
    "\n",
    "# Step 5: Analysis\n",
    "num_ETFs, avg_bonds_portfolio, avg_bonds_basket, avg_basket_frac = hw.analysis()\n",
    "print(num_ETFs, avg_bonds_portfolio, avg_bonds_basket, avg_basket_frac)\n",
    "response = hw.analysis_verbal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
